

# **A Practical Guide to Advanced MLIR API Usage for GPU Code Generation**

## **Introduction: From High-Level Semantics to Hardware-Specific IR**

The Multi-Level Intermediate Representation (MLIR) project provides a novel and extensible infrastructure for building modern compilers.1 A central tenet of its design is the concept of progressive lowering, where high-level, abstract operations are gradually transformed into lower-level, hardware-specific representations. The task of lowering a custom

orchestra.transfer operation to the Intel-specific xegpu dialect is a canonical example of this process. It represents the critical juncture where abstract data movement semantics are translated into a concrete implementation tailored for a specific GPU architecture.

This lowering process, while conceptually straightforward, frequently exposes compiler engineers to the more intricate and idiomatic aspects of the MLIR C++ API. Developers often encounter compilation errors that are not immediately intuitive, as they stem from specific architectural patterns and design principles unique to the MLIR framework. This report addresses three such blockers that are common yet non-trivial:

1. A type mismatch between the generic mlir::Value handle and the strongly-typed mlir::TypedValue\<mlir::MemRefType\> required by target operation builders.  
2. An ambiguous builder signature for creating hardware-specific operations, such as xegpu.fence.  
3. C++ object lifecycle errors related to defining compiler passes with command-line options, specifically the "use of deleted function" error when using mlir::Pass::Option.

This document serves as both a direct solution to these immediate blockers and a durable guide to advanced MLIR C++ development. It begins by providing a single, complete, and self-contained C++ code snippet that resolves all three issues, enabling immediate progress. The subsequent sections then provide a deep-dive analysis of each problem, deconstructing the technical rationale behind the idiomatic solution. By elucidating the underlying design principles, this report aims to equip the compiler engineer with a robust mental model for navigating the MLIR C++ API effectively in future development endeavors.

## **Section 1: The Complete Lowering Snippet: A Self-Contained Solution**

For immediate utility, the following code block presents a complete, self-contained C++ implementation that demonstrates the solutions to all three identified problems. This snippet includes the necessary headers, the full definition of a non-TableGen pass with a command-line option, and the implementation of the lowering function, which correctly handles the type conversion and builder invocation issues. This code is intended to be a working reference that can be integrated directly into the OrchestraOS compiler project. The detailed explanations for *why* these specific API usages are correct are provided in the subsequent sections of this report.

C++

\#**include** "mlir/Dialect/Arith/IR/Arith.h"  
\#**include** "mlir/Dialect/MemRef/IR/MemRef.h"  
\#**include** "mlir/Dialect/SCF/IR/SCF.h"  
\#**include** "mlir/Dialect/XeGPU/IR/XeGPU.h"  
\#**include** "mlir/IR/Builders.h"  
\#**include** "mlir/IR/ImplicitLocOpBuilder.h"  
\#**include** "mlir/Pass/Pass.h"  
\#**include** "mlir/Transforms/DialectConversion.h"

// Forward declaration of the custom Orchestra operation.  
// In a real project, this would be included from the dialect's Ops.h header.  
namespace mlir {  
namespace orchestra {  
class TransferOp;  
} // namespace orchestra  
} // namespace mlir

// Assume a simplified definition for orchestra::TransferOp for this example.  
// In a real scenario, this would be generated by TableGen.  
class mlir::orchestra::TransferOp : public mlir::Op\<mlir::orchestra::TransferOp\> {  
public:  
  using Op::Op;  
  static mlir::StringRef getOperationName() { return "orchestra.transfer"; }  
  mlir::Value getSource() { return getOperand(0); }  
  // Add other accessors as needed...  
};

/// Lowers a single orchestra.transfer operation to a tiled copy loop  
/// using the xegpu dialect.  
void lowerTransferToXeGPU(mlir::OpBuilder \&builder,  
                          mlir::orchestra::TransferOp op) {  
  mlir::Location loc \= op.getLoc();  
  mlir::ImplicitLocOpBuilder b(loc, builder);

  // \=========================================================================  
  // Problem 1 Solution: TypedValue\<MemRefType\> vs. Value Mismatch  
  //  
  // Use \`Value::cast\` to safely convert the generic \`mlir::Value\` to a  
  // \`TypedValue\<MemRefType\>\`. This performs a runtime check and provides  
  // the compiler with the necessary type information for the builder call.  
  // \=========================================================================  
  auto source \= op.getSource();  
  auto sourceTypedVal \= source.cast\<mlir::TypedValue\<mlir::MemRefType\>\>();

  // Create the tensor descriptor for the source memref.  
  auto tdesc \= b.create\<mlir::xegpu::CreateNdDescOp\>(  
      sourceTypedVal, /\*offsets=\*/mlir::ValueRange{},  
      /\*shape=\*/mlir::ValueRange{}, /\*strides=\*/mlir::ValueRange{});

  // Example loop bounds. In a real lowering, these would be derived  
  // from the operation's semantics.  
  auto lowerBound \= b.create\<mlir::arith::ConstantIndexOp\>(0);  
  auto upperBound \= b.create\<mlir::arith::ConstantIndexOp\>(1024);  
  auto step \= b.create\<mlir::arith::ConstantIndexOp\>(64);

  // Create the scf.for loop for tiling.  
  auto forOp \= b.create\<mlir::scf::ForOp\>(  
      lowerBound, upperBound, step, /\*iterArgs=\*/mlir::ValueRange{},  
      \[&\](mlir::OpBuilder \&loopBuilder, mlir::Location loopLoc,  
          mlir::Value iv, mlir::ValueRange iterArgs) {  
        mlir::ImplicitLocOpBuilder loopB(loopLoc, loopBuilder);

        // Inside the loop, create load and store operations.  
        // The actual logic would depend on the tiling strategy.  
        auto loadedValue \=  
            loopB.create\<mlir::xegpu::LoadNdOp\>(tdesc, /\*offsets=\*/iv);

        // For demonstration, assume a destination tdesc is available.  
        // mlir::Value destTdesc \=...;  
        // loopB.create\<mlir::xegpu::StoreNdOp\>(destTdesc, loadedValue, /\*offsets=\*/iv);

        loopB.create\<mlir::scf::YieldOp\>();  
      });

  // \=========================================================================  
  // Problem 2 Solution: Correct Invocation for the xegpu.fence op Builder  
  //  
  // The builder for \`xegpu.fence\` takes the location and a C++ enum value  
  // from the \`mlir::xegpu::FenceScope\` enumeration, which is generated  
  // from the dialect's TableGen definitions.  
  // \=========================================================================  
  b.create\<mlir::xegpu::FenceOp\>(mlir::xegpu::FenceScope::Workgroup);

  // After the lowering, the original operation should be erased.  
  op.erase();  
}

// \=========================================================================  
// Problem 3 Solution: Pass with Command-Line Options without TableGen  
//  
// The \`PassWrapper\` requires a default and a copy constructor. If the pass  
// has non-copyable members like \`mlir::Pass::Option\`, the default copy  
// constructor is deleted.  
//  
// The solution has two parts:  
// 1\. Initialize the \`Option\` member in the constructor's member initializer  
//    list, passing \`\*this\` as the parent.  
// 2\. Provide an explicit, empty copy constructor. This satisfies the  
//    PassManager's \`clone()\` mechanism, which uses the copy constructor to  
//    create a new instance before \`copyOptionValuesFrom()\` transfers the  
//    option state.  
// \=========================================================================  
struct LowerOrchestraToGPUPass  
    : public mlir::PassWrapper\<LowerOrchestraToGPUPass,  
                               mlir::OperationPass\<mlir::ModuleOp\>\> {  
public:  
  // Default constructor is required.  
  LowerOrchestraToGPUPass() \= default;

  // An explicit (often empty) copy constructor is required because  
  // \`mlir::Pass::Option\` is non-copyable, which deletes the implicit  
  // copy constructor for the whole class.  
  LowerOrchestraToGPUPass(const LowerOrchestraToGPUPass \&pass) {}

  StringRef getArgument() const final { return "lower-orchestra-to-gpu"; }  
  StringRef getDescription() const final {  
    return "Lowers Orchestra dialect to a target GPU dialect.";  
  }

  void runOnOperation() override {  
    // Example of using the option.  
    if (gpuBackend.getValue()\!= "xegpu") {  
      getOperation()-\>emitError("This pass currently only supports 'xegpu' backend.");  
      signalPassFailure();  
      return;  
    }

    mlir::ModuleOp module \= getOperation();  
    mlir::OpBuilder builder(module.getContext());

    // Collect the operations to lower.  
    llvm::SmallVector\<mlir::orchestra::TransferOp\> transferOps;  
    module.walk(\[&\](mlir::orchestra::TransferOp op) {  
      transferOps.push\_back(op);  
    });

    // Lower each operation.  
    for (auto op : transferOps) {  
      builder.setInsertionPoint(op);  
      lowerTransferToXeGPU(builder, op);  
    }  
  }

private:  
  // The \`Option\` member must be initialized in the constructor's member  
  // initializer list.  
  mlir::Pass::Option\<std::string\> gpuBackend{  
      \*this, "gpu-backend",  
      llvm::cl::desc("Specify the target GPU backend (e.g., 'xegpu')."),  
      llvm::cl::value\_desc("string"), llvm::cl::init("xegpu")};  
};

## **Section 2: Navigating the MLIR Type Hierarchy: Resolving the Value vs. TypedValue Mismatch**

A frequent source of compilation errors for developers new to the MLIR C++ API is the apparent mismatch between the generic mlir::Value class and the strongly-typed value classes (e.g., mlir::TypedValue\<mlir::MemRefType\>) required by many operation builders. Attempts to use standard C++ casting mechanisms like dynamic\_cast or relying on implicit conversions often fail, leading to confusion. This issue is not a flaw in the API but a direct consequence of a fundamental design principle in MLIR: the separation of a value instance from its type definition.

### **The Value-Type Dichotomy in MLIR**

In MLIR's architecture, mlir::Value is a lightweight, value-semantic handle, essentially a wrapper around a pointer to an underlying implementation object (detail::ValueImpl\*).2 It does not use C++ virtual functions or Run-Time Type Information (RTTI) to encode information about its MLIR type. This design choice is critical for performance, as it avoids the overhead of virtual dispatch for common operations on values and allows

mlir::Value to be passed around cheaply.

Instead of embedding type information in the C++ class hierarchy of Value itself, every mlir::Value instance is paired with a separate mlir::Type object. It is the mlir::Type class and its subclasses (mlir::MemRefType, mlir::IntegerType, etc.) that form a rich C++ class hierarchy. Consequently, all type introspection and casting must be performed on the mlir::Type object associated with a mlir::Value, not on the mlir::Value handle directly.

The canonical, low-level pattern for this process, seen frequently throughout the MLIR codebase, involves two distinct steps 3:

1. **Retrieve the Type:** Get the mlir::Type object from the mlir::Value handle using the getType() method.  
2. **Cast the Type:** Use llvm::cast or llvm::dyn\_cast on the retrieved mlir::Type object to convert it to the desired C++ type.

For example, if source is an mlir::Value that is known to be a memref, the following code correctly extracts its MemRefType:

C++

mlir::Value source \= op.getSource();  
mlir::Type sourceType \= source.getType();  
auto memrefType \= llvm::cast\<mlir::MemRefType\>(sourceType);  
// Now 'memrefType' can be used to query shape, element type, etc.

This explicit, two-step process correctly follows MLIR's design by operating on the type hierarchy where it actually exists. The failure of mlir::dyn\_cast\<mlir::MemRefType\>(op.getSource()) is now clear: it attempts to perform a C++ cast on a class hierarchy (mlir::Value) that does not mirror the MLIR type system.

### **The Idiomatic Solution: Value::cast**

While the two-step getType() and llvm::cast() pattern is functionally correct, it is verbose. Recognizing the frequency of this pattern, the MLIR API provides a more convenient and idiomatic mechanism through the mlir::Value::cast family of methods. These methods serve as syntactic sugar, combining the type retrieval and casting into a single, expressive call.

The value.cast\<T\>() method is a template method that can be used to convert a generic mlir::Value into a more specific, typed handle. When used with a TypedValue specialization, such as mlir::TypedValue\<mlir::MemRefType\>, it performs the following actions:

1. It internally calls getType() on the mlir::Value.  
2. It performs a checked cast of the resulting mlir::Type to mlir::MemRefType. If the cast fails, it triggers an assertion, as cast implies that the conversion is expected to succeed.  
3. On success, it returns a mlir::TypedValue\<mlir::MemRefType\>, which is a compile-time wrapper that provides both the original mlir::Value and the strongly-typed mlir::MemRefType.

This single line is the modern, idiomatic solution to the problem:

C++

auto sourceTypedVal \= op.getSource().cast\<mlir::TypedValue\<mlir::MemRefType\>\>();

This sourceTypedVal can then be passed directly to the xegpu::CreateNdDescOp builder. The C++ compiler now has the static type information it needs to select the correct builder overload, resolving the original compilation error. This approach is not only more concise but also safer, as it encapsulates the necessary runtime check within a single, clear API call.

## **Section 3: From Declarative Syntax to Imperative Code: Invoking the xegpu.fence Builder**

The second challenge, identifying the correct C++ builder invocation for xegpu.fence, highlights another core aspect of MLIR development: the role of TableGen as the single source of truth for operation definitions. When the C++ builder signature for an operation appears ambiguous or is not immediately discoverable in header files, the definitive specification is always located in the dialect's declarative .td (TableGen definition) files.4

### **TableGen as the Single Source of Truth**

MLIR operations are not typically defined imperatively in C++. Instead, their properties—such as name, arguments, results, and attributes—are declared in .td files.5 The

mlir-tblgen tool processes these declarative descriptions to auto-generate a significant amount of C++ boilerplate, including the operation's C++ class definition, parsers, printers, and, most importantly for this problem, its OpBuilder methods.7 Understanding how to map the declarative syntax of a

.td file to the generated C++ API is a fundamental skill for MLIR developers.

The definition for the xegpu.fence operation within XeGPUOps.td (referenced by XeGPU.td 8) is the blueprint for its C++ interface. While the exact file is not provided, its structure can be inferred from the dialect's documentation.9 The documentation for

xegpu.fence lists an attribute named fence\_scope of type ::mlir::xegpu::FenceScopeAttr. The documentation further specifies that FenceScope is an enum with possible values "workgroup" and "gpu".

A typical TableGen definition for such an operation would look like this:

Code-Snippet

// Definition for the FenceScope enum attribute  
def FenceScopeAttr : EnumAttr\<XeGPU\_Dialect, FenceScope, "fence\_scope"\>;

// Definition for the FenceOp operation  
def FenceOp : XeGPU\_Op\<"fence"\> {  
  let summary \= "A memory fence with a specified scope.";  
  let arguments \= (ins FenceScopeAttr:$fence\_scope);  
  //... other properties  
}

This declarative definition provides all the information needed to construct the C++ builder call.

### **The Mechanical Translation to C++**

The process of translating the TableGen definition to a C++ builder call is methodical:

1. **Identify Arguments:** The arguments section of the FenceOp definition lists its operands and attributes. In this case, it has one attribute, $fence\_scope, of type FenceScopeAttr.  
2. **Identify the Attribute Type:** The FenceScopeAttr is an EnumAttr. TableGen generates a corresponding C++ enum class for this attribute, which by convention will be named mlir::xegpu::FenceScope. The enum's members will correspond to the declared values, so "workgroup" becomes FenceScope::Workgroup.  
3. **Construct the Builder Call:** The generic OpBuilder::create\<OpTy\>(...) method is the primary way to create operations.10 Its arguments map directly to the operation's definition. The first argument is always the  
   mlir::Location. Subsequent arguments correspond to the results, operands, and attributes defined in the .td file. For an EnumAttr, the create method is overloaded to accept the corresponding C++ enum class value directly. MLIR's builder infrastructure automatically handles the conversion from the C++ enum value to the appropriate MLIR Attribute instance.

This mechanical translation leads directly to the correct, unambiguous C++ one-liner for creating an xegpu.fence operation with a workgroup scope:

C++

builder.create\<mlir::xegpu::FenceOp\>(op.getLoc(), mlir::xegpu::FenceScope::Workgroup);

This invocation is type-safe and directly reflects the operation's declarative definition. The initial ambiguity is resolved not by searching through header files for a specific function signature, but by consulting the .td file as the authoritative contract for the operation's API.

## **Section 4: Architecting Compiler Passes: Correctly Implementing a PassWrapper with Options**

The third problem—a "use of deleted function" error when adding an mlir::Pass::Option to a pass class—is the most subtle, as it lies at the intersection of C++ object lifecycle rules and the specific architectural design of the MLIR Pass Manager. The error message correctly indicates that the compiler is attempting to use a copy constructor or copy-assignment operator that has been deleted, which happens because the pass class has become non-copyable.

### **The Non-Copyable Nature of mlir::Pass**

The fundamental reason for this issue is that the mlir::Pass base class is intentionally designed to be non-copyable.11 Its copy constructor and copy-assignment operator are explicitly deleted. This is a crucial design choice that ensures the integrity of the pass infrastructure for several reasons:

* **State Management:** A pass is a stateful object. It contains options that configure its behavior and statistics that record its actions. Uncontrolled copying would lead to ambiguity about which copy holds the authoritative state.  
* **Pass Manager Ownership:** The Pass Manager is responsible for the lifecycle of passes. It creates, initializes, and runs them. Allowing passes to be freely copied would violate this ownership model.  
* **Multithreading:** In a multithreaded compilation pipeline, the Pass Manager may *clone* a pass to run it on different operations in parallel.11 This cloning is a deliberate, controlled process distinct from simple copying. The non-copyable nature of  
  Pass forces developers to adhere to the Pass Manager's controlled duplication mechanism.

When an mlir::Pass::Option is added as a member to a pass struct, the C++ compiler checks if the entire struct can still be copy-constructed. The mlir::Pass::Option class itself is non-copyable. Therefore, by adding it as a member, the compiler implicitly deletes the default copy constructor for the entire pass struct. Any code that subsequently requires a copy of the pass, including parts of the Pass Manager's cloning mechanism, will fail to compile, resulting in the "use of deleted function" error.

### **The Canonical C++ Structure for a Pass with Options**

The correct implementation requires addressing two distinct C++ requirements: the construction of the Option member itself, and the provision of a copy constructor for the pass that is compatible with the Pass Manager.

#### **1\. Correct Option Construction via Member Initializer List**

The constructor for mlir::Pass::Option requires a reference to its parent pass (Pass \&parent) as its first argument.12 This design ensures that every option is inextricably linked to the specific pass instance it configures. This constructor signature means that an

Option member cannot be default-constructed. The only way to correctly initialize such a member in C++ is in the constructor's member initializer list.

The correct pattern is to pass \*this to the Option's constructor, explicitly binding the option to the pass instance being created:

C++

struct MyPass : public mlir::PassWrapper\<...\> {  
  //...

private:  
  mlir::Pass::Option\<std::string\> myOption{  
      \*this, "my-option-arg", llvm::cl::desc("Description..."),...};  
};

This correctly initializes the myOption member during the construction of MyPass. Any attempt to initialize it inside the constructor body would be too late and would result in a compilation error.

#### **2\. Satisfying the Pass Manager's clone() Mechanism**

Even with correct initialization, the pass class is now non-copyable. The Pass Manager's clone() method, which is essential for the pass pipeline, relies on a virtual clonePass() method.12 The default implementation of

clonePass() in PassWrapper attempts to create a new pass instance using the pass's copy constructor.14 Since the implicit copy constructor has been deleted, this will fail.

The solution is to provide an explicit, user-defined copy constructor for the pass. This constructor can often be empty:

C++

struct MyPass : public mlir::PassWrapper\<...\> {  
public:  
  MyPass() \= default;  
  MyPass(const MyPass& other) { /\* can be empty \*/ }  
  //...  
};

By providing this constructor, the developer signals to the C++ compiler that they are taking responsibility for how the object is copied. This satisfies the requirement of the clonePass() method, allowing a new instance of the pass to be created. The Pass Manager's clone() method then completes the process by calling copyOptionValuesFrom(), which correctly transfers the state of all registered options from the original pass to the new clone without invoking any problematic member-wise copying.11 This two-part solution—member initializer list for construction and an explicit copy constructor for cloning—fully resolves the issue and aligns the pass implementation with the architectural requirements of the MLIR Pass Manager.

## **Section 5: Synthesis and Best Practices for MLIR C++ Development**

The resolution of the three specific blockers in the orchestra.transfer to xegpu lowering task reveals a set of underlying principles for effective MLIR C++ development. These principles, once internalized, provide a robust framework for solving not just these particular issues, but a wide class of similar API challenges. Moving from a trial-and-error approach to a model-based understanding of the framework's design is the key to becoming a proficient MLIR developer.

The core lessons derived from this analysis can be summarized as follows:

1. **The Type is the Contract:** In MLIR, the mlir::Type class hierarchy, not the mlir::Value handle, is the locus of type-specific information and behavior. All type-related queries, checks, and casts must operate on the object returned by value.getType(). For idiomatic and safe conversions, the value.cast\<...\>() family of methods should be the preferred tool, as it encapsulates the underlying mechanics in a clean and expressive API.  
2. **TableGen is the Blueprint:** An operation's .td file is its definitive specification. It serves as the single source of truth from which the C++ class, its builders, and other utilities are generated. When faced with ambiguity about an operation's C++ API, particularly its builder signature, the first and most reliable resource to consult is its declarative TableGen definition. Learning to map .td constructs to their corresponding C++ artifacts is a fundamental skill.  
3. **Respect Object Lifecycles:** The MLIR C++ framework, especially the pass infrastructure, employs a strict object lifecycle and ownership model to ensure state integrity and enable advanced features like multithreading. Classes like mlir::Pass are intentionally non-copyable. Correctly implementing features like pass options requires adherence to C++ rules for object construction (i.e., using member initializer lists) and an understanding of the specific cloning mechanisms employed by the Pass Manager.

To further crystallize these principles, the following table contrasts the common but incorrect approaches with the idiomatic MLIR C++ solutions, providing a quick-reference guide for future development.

| Problem Domain | Common (but Incorrect) Attempt | Idiomatic MLIR C++ Solution | Rationale |
| :---- | :---- | :---- | :---- |
| **Type Conversion** | mlir::dyn\_cast\<MemRefType\>(value) or implicit conversion. | auto typed \= value.cast\<mlir::TypedValue\<mlir::MemRefType\>\>(); | mlir::Value is a generic handle; casting must occur on its associated mlir::Type object. The cast method provides a safe and concise API for this. |
| **Builder Invocation** | builder.create\<FenceOp\>(loc, "workgroup") | builder.create\<mlir::xegpu::FenceOp\>(loc, mlir::xegpu::FenceScope::Workgroup); | Builders expect type-safe C++ enums or other specific C++ types that are auto-generated from the operation's TableGen definition, not raw strings or generic attributes. |
| **Pass Options** | Declaring Option as a member without a custom constructor. | Option\<T\> opt{\*this,...}; in the member initializer list, plus an explicit copy constructor for the pass. | mlir::Pass is non-copyable. Options must be explicitly bound to their unique pass instance upon construction, and the pass must be made copy-constructible to work with the Pass Manager's cloning mechanism. |

## **Conclusion**

The challenges encountered during the implementation of the orchestra.transfer lowering are representative of the learning curve associated with mastering MLIR's sophisticated C++ API. The solutions are not arbitrary but are deeply rooted in the framework's core design philosophy, which prioritizes extensibility, performance, and safety. By understanding the strict separation between Value and Type, recognizing TableGen as the authoritative source for operation APIs, and respecting the Pass Manager's object lifecycle model, developers can move beyond resolving individual compilation errors to writing code that is robust, maintainable, and idiomatic. The principles and patterns detailed in this report provide a foundational understanding that will empower developers to confidently and effectively leverage the full power of the MLIR infrastructure for complex compiler development tasks.
